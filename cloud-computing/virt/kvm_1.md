# KVM虚拟化
## KVM哲学
KVM起源于一个短短的只有几千行代码的kernel patch，但是其性能却能够**逼近物理机性能的90%**。与Xen不同，KVM完全依赖于CPU的硬件虚拟化方案，可以说，从本质上看，**KVM就是一个对CPU硬件虚拟化单元的操作patch**，体现*nix的哲学思想是：**只做一件事情，但是要把这件事情做好**。

KVM的思想是在Linux内核的基础上添加虚拟机管理模块，重用Linux内核中已经完善的进程调度、内存管理、IO管理等部分，使之成为一个可以支持运行虚拟机的Hypervisor。因此，KVM并不是一个完整的模拟器，而只是一个提供了虚拟化功能的内核插件，具体的模拟器工作是借助QEMU来完成的。

## KVM虚拟化原理
KVM是基于**硬件虚拟化扩展**（Intel VT或者AMD-V）技术，是**Linux完全原生**的**全虚拟化**解决方案。
KVM包含一个可加载的Kernel module: kvm.ko和一个处理器相关的module：kvm-intel.ko（或者kvm-amd.ko）。
KVM的io_ctl接口可以管理**vcpu**和**内存**，为vcpu注入中断和提供时钟信号，而kvm本身没有提供设备的模拟。设备模拟需要应用层软件Qemu来实现。这种架构保证了kvm避免了繁琐的设备模拟和设备驱动部分。

KVM模块是KVM虚拟机的核心部分。其主要功能个功能是初始化CPU硬件，打开**虚拟化模式**，然后将虚拟客户机运行在**非根模式**（**客户机模式**）下，并对虚拟客户机的运行提供一定的支持。KVM仅支持硬件虚拟化。打开并初始化系统硬件以支持虚拟机的运行，是KVM模块的职责所在。在被内载加载的时候，KVM模块会先**初始化内部的数据结构**；做好准备之后，KVM模块检测系统当前的CPU，然后打开CPU控制寄存器CR4中的虚拟化模式开关；通过执行VMXON指令将宿主操作系统（包括KVM模块本身）置于虚拟化模式中的**根模式**（**内核模式**）；最后，KVM模块创建特殊设备文件/dev/kvm并等待来自用户空间的命令（QEMU）。接下来，虚拟机的创建和运行将是一个**用户空间**的应用程序**QEMU和KVM模块**相互配合的过程。

KVM模块与用户空间QEMU的通信接口主要是一系列针对**特殊设备文件（/dev/kvm）的IOCTL调用**。KVM模块加载之初，只存在/dev/kvm文件，而针对该文件等最重IOCTL调用就是“创建虚拟机”。在这里“创建虚拟机”可以理解成KVM为了某个特定的虚拟客户机（用户空间程序创建并初始化）创建对应的**内核数据结构**，同时KVM还会返回**一个文件句柄来代表所创建的虚拟机**。针对该文件句柄的IOCTL调用可以对虚拟机做相应的管理，比如创建用户空间虚拟地址和客户机物理地址及真实内存物理地址的映射关系，再比如创建多个可供运行的虚拟处理器（vCPU）。同样，KVM模块会为每一个创建出来的vCPU生成对一个的文件句柄，对vCPU相应的文件句柄进行相应的IOCTL调用，就可以对vCPU进行管理。

针对vCPU最重要的IOCTL调用就是“执行vCPU”。通过它，用户空间准备好的虚拟机在KVM模块的支持下，被置于虚拟化模式中的**非根模式**（**客户机模式**）下，开始执行二进制指令，在该模式下，所有敏感的二进制指令都会被处理器捕捉到，处理器在保存现场之后自动切换到**根模式**（**内核模式**），由KVM决定进一步处理（要么由KVM模块直接处理，要么返回用户空间交由用户空间程序QEMU处理**用户模式**）。

在KVM架构中，虚拟机实现为常规的Linux进程，由标准的Linux调度程序进行调度。事实上，每个虚拟CPU显示为一个常规的Linux线程。

KVM本身不执行任何模拟，需要用户空间应用程序(QEMU)通过/dev/kvm接口设置一个客户机虚拟服务器的地址空间，向它提供模拟的I/O，并将它的视频显示映射回宿主的显示屏。

利用VT-x技术的支持，KVM中的每个虚拟机可具有多个虚拟处理器VCPU，每个VCPU对应一个Qemu线程。VCPU的创建、初始化、运行以及退出处理都在Qemu线程上下文中进行，需要**Kernel、User和Guest**三种模式相互配合。

* Qemu线程与KVM内核模块间以ioctl的方式进行交互
* KVM内核模块与客户软件之间通过VM Exit和VM entry操作进行切换

```sh
s->fd = qemu_open("/dev/kvm", O_RDWR);
ret = kvm_ioctl(s, KVM_GET_API_VERSION, 0);
s->vmfd = kvm_ioctl(s, KVM_CREATE_VM, 0);
...............................
ret = kvm_vm_ioctl(s, KVM_CREATE_VCPU, env->cpu_index);
.............................
env->kvm_fd = ret;
run_ret = kvm_vcpu_ioctl(env, KVM_RUN, 0);
```


KVM提供了一个设备/dev/kvm，对KVM的控制要通过这个设备提供的io_ctl接口实现。这是linux内核提供服务的最通用方式。

KVM提供了三种概念，分别通过不同的io_ctl接口来控制：
* kvm：代表kvm模块本身，用来管理kvm版本信息，创建一个vm。
* vm：代表一个虚拟机。通过vm的io_ctl接口，可以为虚拟机创建vcpu，设置内存区间，创建中断控制芯片，分配中断等等。
* vcpu：代表一个vcpu。通过vcpu的io_ctl接口，可以启动或者暂停vcpu，设置vcpu的寄存器，为vcpu注入中断等等。

Qemu的使用方式，首先是打开/dev/kvm设备，通过**KVM_Create_VM**创建一个虚拟机对象，然后通过**KVM_CREATE_VCPU**为虚拟机创建vcpu对象，最后通过**KVM_RUN**设置vcpu运行起来。因为是简化的代码，中断芯片的模拟，内存的模拟，寄存器的设置等等都已经省略了。
